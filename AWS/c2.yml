---
# AWS C2 Server Deployment Playbook

- name: Deploy AWS C2 server
  hosts: localhost
  gather_facts: false
  connection: local
  vars_files:
    - vars.yaml
  vars:
    # Default values
    ssh_user: "{{ ssh_user | default('kali') }}"
    aws_region: "{{ aws_region | default(aws_region_choices | random) }}"
    instance_type: "{{ aws_instance_type | default('t2.medium') }}"
    deployment_id: "{{ deployment_id | default('') }}"
    c2_name: "{{ c2_name | default('s-' + deployment_id) }}"
    # Check for shared infrastructure
    # Only use shared when C2 and redirector are in the same region
    use_shared_infra: "{{ not (c2_region is defined and redirector_region is defined and c2_region != redirector_region) and not c2_only | default(false) | bool and not redirector_only | default(false) | bool }}"
    # AMI map comes from vars.yaml - add fallback for safety
    kali_ami_map_fallback:
      us-east-1: "ami-061b17d332829ab1c"
      us-east-2: "ami-061b17d332829ab1c"  # Fallback to us-east-1 AMI

  tasks:
    - name: Validate AWS credentials
      assert:
        that:
          - aws_access_key is defined and aws_access_key != ""
          - aws_secret_key is defined and aws_secret_key != ""
        fail_msg: "AWS credentials are required"

    # Load shared infrastructure state if available
    - name: Check for shared infrastructure state
      stat:
        path: "infrastructure_state_{{ deployment_id }}.json"
      register: infra_state_file
      when: use_shared_infra | bool
      
    - name: Load shared infrastructure state
      include_vars:
        file: "infrastructure_state_{{ deployment_id }}.json"
        name: shared_infra
      when: use_shared_infra | bool and infra_state_file.stat.exists | default(false)
      
    - name: Set region for C2
      set_fact:
        aws_c2_region: "{{ shared_infra.region | default(aws_region) }}"
      when: use_shared_infra | bool and infra_state_file.stat.exists | default(false)
        
    - name: Set default region for C2
      set_fact:
        aws_c2_region: "{{ c2_region | default(aws_region) }}"
      when: not (use_shared_infra | bool and infra_state_file.stat.exists | default(false))

    - name: Check if ami_map is provided in vars.yaml
      debug:
        msg: "ami_map is {{ 'defined' if ami_map is defined else 'NOT defined' }} in vars.yaml"

    - name: Set AMI ID for selected region (from vars.yaml)
      set_fact:
        ami_id: "{{ ami_map[aws_c2_region] | default(ami_map.us-east-1) }}"
      when: ami_map is defined and ami_map

    - name: Set AMI ID for selected region (fallback)
      set_fact:
        ami_id: "{{ kali_ami_map_fallback[aws_c2_region] | default(kali_ami_map_fallback['us-east-1']) }}"
      when: ami_id is not defined or ami_id == ""

    - name: Ensure we have a valid AMI ID
      assert:
        that:
          - ami_id is defined and ami_id != ""
        fail_msg: "Could not determine a valid AMI ID for region {{ aws_c2_region }}. Please add it to ami_map in vars.yaml."

    # Add AMI username mapping - improved with better detection
    - name: Determine correct SSH user for the AMI
      set_fact:
        ami_ssh_user: "{{ 'kali' if (ami_id is defined and ami_id is search('-kali-')) or (ami_id is defined and ami_id == 'ami-061b17d332829ab1c') else 'ubuntu' }}"

    - name: Display AMI and user information for debugging
      debug:
        msg: 
          - "Using AMI ID: {{ ami_id | default('AMI not defined') }}"
          - "Detected SSH user: {{ ami_ssh_user }}"

    # Fix: Use the deployment_id key name if c2deploy prefix exists (for consistency with tool scripts)
    - name: Create EC2 key pair with consistent naming
      amazon.aws.ec2_key:
        name: "c2deploy_{{ deployment_id }}"
        region: "{{ aws_c2_region }}"
        state: present
      register: c2_key_pair

    - name: Save private key with consistent naming
      copy:
        content: "{{ c2_key_pair.key.private_key }}"
        dest: "~/.ssh/c2deploy_{{ deployment_id }}.pem"
        mode: "0600"
      when: c2_key_pair.changed and c2_key_pair.key.private_key is defined

    # Create new infrastructure only if not using shared
    - name: Create VPC
      amazon.aws.ec2_vpc_net:
        name: "{{ c2_name }}-vpc"
        cidr_block: "10.0.0.0/16"
        region: "{{ aws_c2_region }}"
        tags:
          Name: "{{ c2_name }}-vpc"
          deployment_id: "{{ deployment_id }}"
        state: present
      register: vpc_result
      when: not (use_shared_infra | bool and infra_state_file.stat.exists | default(false))

    - name: Create internet gateway for VPC
      amazon.aws.ec2_vpc_igw:
        vpc_id: "{{ vpc_result.vpc.id }}"
        region: "{{ aws_c2_region }}"
        state: present
        tags:
          Name: "{{ c2_name }}-igw"
          deployment_id: "{{ deployment_id }}"
      register: igw_result
      when: not (use_shared_infra | bool and infra_state_file.stat.exists | default(false))

    - name: Create subnet in VPC
      amazon.aws.ec2_vpc_subnet:
        vpc_id: "{{ vpc_result.vpc.id }}"
        cidr: "10.0.1.0/24"
        region: "{{ aws_c2_region }}"
        az: "{{ aws_c2_region }}a"
        map_public: yes
        tags:
          Name: "{{ c2_name }}-subnet"
          deployment_id: "{{ deployment_id }}"
      register: subnet_result
      when: not (use_shared_infra | bool and infra_state_file.stat.exists | default(false))

    - name: Create routing table for internet access
      amazon.aws.ec2_vpc_route_table:
        vpc_id: "{{ vpc_result.vpc.id }}"
        region: "{{ aws_c2_region }}"
        tags:
          Name: "{{ c2_name }}-rtb"
          deployment_id: "{{ deployment_id }}"
        routes:
          - dest: "0.0.0.0/0"
            gateway_id: "{{ igw_result.gateway_id }}"
        subnets:
          - "{{ subnet_result.subnet.id }}"
      register: route_table_result
      when: not (use_shared_infra | bool and infra_state_file.stat.exists | default(false))

    # Set VPC ID based on shared or created
    - name: Set VPC ID from shared infrastructure
      set_fact:
        vpc_id: "{{ shared_infra.vpc_id }}"
        subnet_id: "{{ shared_infra.subnet_id }}"
        c2_vpc_id: "{{ shared_infra.vpc_id }}"  # Store for cleanup reference
      when: use_shared_infra | bool and infra_state_file.stat.exists | default(false)

    - name: Set VPC ID from created infrastructure
      set_fact:
        vpc_id: "{{ vpc_result.vpc.id }}"
        subnet_id: "{{ subnet_result.subnet.id }}"
        c2_vpc_id: "{{ vpc_result.vpc.id }}"  # Store for cleanup reference
      when: not (use_shared_infra | bool and infra_state_file.stat.exists | default(false))

    # Create security group
    - name: Create security group
      amazon.aws.ec2_security_group:
        name: "{{ c2_name }}-sg"
        description: "Security group for C2 {{ c2_name }}"
        vpc_id: "{{ vpc_id }}"
        region: "{{ aws_c2_region }}"
        rules:
          - proto: tcp
            ports:
              - 22
              - "{{ havoc_teamserver_port | default(40056) }}"
              - "{{ havoc_http_port | default(8080) }}"
              - "{{ gophish_admin_port }}"
            cidr_ip: 0.0.0.0/0
        rules_egress:
          - proto: -1
            cidr_ip: 0.0.0.0/0
        state: present
      register: security_group

    # Launch the C2 server - use the consistent key pair name
    - name: Launch C2 instance
      amazon.aws.ec2_instance:
        name: "{{ c2_name }}"
        key_name: "c2deploy_{{ deployment_id }}"  # Use the same key name as created above
        instance_type: "{{ instance_type | default('t2.medium') }}"
        vpc_subnet_id: "{{ subnet_id }}"
        security_groups:
          - "{{ security_group.group_id }}"
        image_id: "{{ ami_id }}"
        region: "{{ aws_c2_region }}"
        state: present
        wait: yes
        volumes:
          - device_name: "/dev/xvda"
            ebs:
              volume_size: 100
              delete_on_termination: true
        tags:
          Name: "{{ c2_name }}"
          deployment_id: "{{ deployment_id }}"
      register: c2_instance

    - name: Set c2_ip for later use
      set_fact:
        c2_ip: "{{ c2_instance.instances[0].public_ip_address }}"
        c2_instance_id: "{{ c2_instance.instances[0].instance_id }}"

    - name: Display C2 instance details for debugging
      debug:
        msg:
          - "C2 IP: {{ c2_ip }}"
          - "C2 Instance ID: {{ c2_instance_id }}"
          - "SSH User to use: {{ ami_ssh_user }}"
          - "SSH Key path: ~/.ssh/c2deploy_{{ deployment_id }}.pem"

    - name: Wait for C2 instance initialization
      pause:
        seconds: 180
      when: c2_instance.changed

    - name: Set correct permissions on SSH key
      file:
        path: "~/.ssh/c2deploy_{{ deployment_id }}.pem"
        mode: "0600"

    - name: Wait for C2 SSH to be available
      wait_for:
        host: "{{ c2_ip }}"
        port: 22
        delay: 30
        timeout: 300
        state: started

    # Test SSH connection directly to verify key is working
    - name: Test SSH connection to verify key
      shell: "ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o IdentitiesOnly=yes -i ~/.ssh/c2deploy_{{ deployment_id }}.pem {{ ami_ssh_user }}@{{ c2_ip }} 'echo SSH CONNECTION SUCCESSFUL'"
      register: ssh_test
      ignore_errors: yes

    - name: Display SSH test results
      debug:
        msg: "{{ ssh_test.stdout | default('SSH Connection failed!') }}"

    - name: Add C2 to inventory with updated SSH key path
      add_host:
        name: "c2"
        groups: "c2servers"
        ansible_host: "{{ c2_ip }}"
        ansible_user: "{{ ami_ssh_user }}"
        ansible_ssh_private_key_file: "~/.ssh/c2deploy_{{ deployment_id }}.pem"
        ansible_ssh_common_args: "-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o IdentitiesOnly=yes"
        ansible_python_interpreter: "/usr/bin/python3"
        # Add these lines to pass all required variables:
        smtp_auth_user: "{{ smtp_auth_user }}"
        smtp_auth_pass: "{{ smtp_auth_pass }}"
        gophish_admin_port: "{{ gophish_admin_port }}"
        domain: "{{ domain }}"
        redirector_subdomain: "{{ redirector_subdomain }}"
        letsencrypt_email: "{{ letsencrypt_email }}"
        havoc_teamserver_port: "{{ havoc_teamserver_port | default(40056) }}"
        havoc_http_port: "{{ havoc_http_port | default(8080) }}"
        havoc_https_port: "{{ havoc_https_port | default(443) }}"
        zero_logs: "{{ zero_logs | default(true) }}"
        secure_memory: "{{ secure_memory | default(true) }}"
        disable_history: "{{ disable_history | default(true) }}"
        setup_integrated_tracker: "{{ setup_integrated_tracker | default(false) }}"
        tracker_domain: "{{ tracker_domain | default('track.' + domain) | default('') }}"

# Configure C2 server with a proper structure
- name: Configure C2 server
  hosts: c2servers
  become: yes
  gather_facts: true
  vars_files:
    - vars.yaml  # Add this line to load the variables
  vars:
    redirector_ip: "{{ hostvars['localhost']['redirector_ip'] | default('127.0.0.1') }}"
    c2_subdomain: "{{ c2_subdomain | default('mail') }}"
  tasks:
    - name: Install python3 if it doesn't exist on target
      raw: test -e /usr/bin/python3 || (apt-get update && apt-get install -y python3)
      args:
        executable: /bin/bash
      register: python_install
      ignore_errors: yes
      
    - name: Debug connection information
      debug:
        msg:
          - "Connected to C2 server successfully"
          - "Host: {{ ansible_host }}"
          - "User: {{ ansible_user }}"
          - "Python version: {{ ansible_python_version | default('unknown') }}"
      
    - name: Download Kali archive keyring to temporary location
      get_url:
        url: https://archive.kali.org/archive-keyring.gpg
        dest: /tmp/kali-archive-keyring.gpg
        mode: "0644"
        force: yes
      register: keyring_download

    - name: Install Kali archive keyring
      command: install -m 0644 /tmp/kali-archive-keyring.gpg /usr/share/keyrings/kali-archive-keyring.gpg
      when: keyring_download is changed

    - name: Wait for apt to be available
      apt:
        update_cache: yes
      register: apt_result
      until: apt_result is success
      retries: 10
      delay: 10

    - name: Install Rust compiler
      apt:
        name:
          - cargo
          - rustc
          - libssl-dev
          - pkg-config
        state: present
      register: rust_install
      until: rust_install is success
      retries: 3
      delay: 5

    - name: Clean up any failed pipx installations
      file:
        path: "{{ item }}"
        state: absent
      with_items:
        - "/root/.local/state/pipx/venvs/netexec"
        - "/root/.local/state/pipx/venvs/trevorspray"
      ignore_errors: yes

    - name: Include common tool installation tasks
      include_tasks: "../tasks/install_tools.yml"

    - name: Include common C2 configuration tasks
      include_tasks: "../tasks/configure_c2.yml"

    - name: Include common mail server configuration tasks
      include_tasks: "../tasks/configure_mail.yml"
      
    - name: Print deployment summary
      debug:
        msg:
          - "C2 Server Deployment Complete!"
          - "-----------------------------"
          - "C2 Server IP: {{ ansible_host }}"
          - "C2 Server Domain: {{ c2_subdomain }}.{{ domain }} (Update DNS A record)"
          - "GoPhish Admin Port: {{ gophish_admin_port }}"
          - "SSH Key: ~/.ssh/c2deploy_{{ hostvars['localhost']['deployment_id'] }}.pem"
      when: not disable_summary | default(false)